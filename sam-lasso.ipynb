{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4a12c6",
   "metadata": {},
   "source": [
    "### SAM For LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1edcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62a4e99794445dfb012bd14b780722a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sim runs:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n   p  flip_y corr  loss_base  loss_sam  acc_base  acc_sam  delta_loss  delta_acc  reps  p_loss\n",
      " 4000 200  0.0500 high     0.6248    0.6169    0.6883   0.6936     -0.0078     0.0054    20  0.0000\n",
      " 4000 200  0.0500  low     0.5392    0.5291    0.7727   0.7772     -0.0102     0.0045    20  0.0000\n",
      " 4000 200  0.2500 high     0.6642    0.6583    0.6275   0.6328     -0.0059     0.0053    20  0.0000\n",
      " 4000 200  0.2500  low     0.6185    0.6108    0.6919   0.6961     -0.0077     0.0041    20  0.0000\n",
      " 4000 500  0.0500 high     0.6670    0.6597    0.6250   0.6380     -0.0073     0.0130    20  0.0000\n",
      " 4000 500  0.0500  low     0.5996    0.5880    0.7257   0.7339     -0.0116     0.0083    20  0.0000\n",
      " 4000 500  0.2500 high     0.6846    0.6800    0.5788   0.5924     -0.0046     0.0136    20  0.0000\n",
      " 4000 500  0.2500  low     0.6534    0.6445    0.6556   0.6658     -0.0089     0.0102    20  0.0000\n",
      "20000 200  0.0500 high     0.6285    0.6204    0.6834   0.6889     -0.0081     0.0055    20  0.0000\n",
      "20000 200  0.0500  low     0.5417    0.5307    0.7712   0.7762     -0.0110     0.0050    20  0.0000\n",
      "20000 200  0.2500 high     0.6651    0.6589    0.6333   0.6363     -0.0062     0.0030    20  0.0000\n",
      "20000 200  0.2500  low     0.6195    0.6105    0.6980   0.7051     -0.0090     0.0071    20  0.0000\n",
      "20000 500  0.0500 high     0.6687    0.6591    0.6444   0.6546     -0.0095     0.0102    20  0.0000\n",
      "20000 500  0.0500  low     0.5963    0.5842    0.7419   0.7468     -0.0121     0.0049    20  0.0000\n",
      "20000 500  0.2500 high     0.6892    0.6844    0.5660   0.5873     -0.0048     0.0212    20  0.0000\n",
      "20000 500  0.2500  low     0.6555    0.6449    0.6681   0.6765     -0.0106     0.0084    20  0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import itertools, joblib, warnings, os, sys\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1. Helper functions (define *before* run_once for joblib)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def soft_thresh(w, tau):\n",
    "    return np.sign(w) * np.maximum(np.abs(w) - tau, 0.)\n",
    "\n",
    "def pg_lasso(Xtr, ytr, lam, lr=0.1, n_iter=120):\n",
    "    n, p = Xtr.shape\n",
    "    w = np.zeros(p)\n",
    "    for _ in range(n_iter):\n",
    "        grad = Xtr.T @ (sigmoid(Xtr @ w) - ytr) / n\n",
    "        w -= lr * grad\n",
    "        w = soft_thresh(w, lr * lam)\n",
    "    return w\n",
    "\n",
    "def sam_pg_lasso(Xtr, ytr, lam, lr=0.1, rho=0.05, n_iter=120):\n",
    "    n, p = Xtr.shape\n",
    "    w = np.zeros(p)\n",
    "    for _ in range(n_iter):\n",
    "        grad = Xtr.T @ (sigmoid(Xtr @ w) - ytr) / n\n",
    "        gnorm = np.linalg.norm(grad)\n",
    "        w_adv = w + rho * grad / gnorm if gnorm > 0 else w\n",
    "        grad_adv = Xtr.T @ (sigmoid(Xtr @ w_adv) - ytr) / n\n",
    "        w -= lr * grad_adv\n",
    "        w = soft_thresh(w, lr * lam)\n",
    "    return w\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2.  One replicate runner (needs helpers already defined)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def run_once(params, seed, lam=0.05, rho=0.05):\n",
    "    n, p, flip_y, corr = params\n",
    "    sep = 1.0 if corr == \"low\" else 0.7\n",
    "    X, y = make_classification(\n",
    "        n_samples=n, n_features=p,\n",
    "        n_informative=int(0.2 * p),\n",
    "        n_redundant=int(0.2 * p),\n",
    "        flip_y=flip_y, class_sep=sep,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    Xtr, Xtmp, ytr, ytmp = train_test_split(\n",
    "        X, y, test_size=0.4, stratify=y, random_state=seed\n",
    "    )\n",
    "    Xval, Xte, yval, yte = train_test_split(\n",
    "        Xtmp, ytmp, test_size=0.5, stratify=ytmp, random_state=seed\n",
    "    )\n",
    "\n",
    "    w0 = pg_lasso(Xtr, ytr, lam)\n",
    "    w1 = sam_pg_lasso(Xtr, ytr, lam, rho=rho)\n",
    "\n",
    "    loss0 = log_loss(yte, sigmoid(Xte @ w0))\n",
    "    loss1 = log_loss(yte, sigmoid(Xte @ w1))\n",
    "    acc0  = accuracy_score(yte, (sigmoid(Xte @ w0) > 0.5))\n",
    "    acc1  = accuracy_score(yte, (sigmoid(Xte @ w1) > 0.5))\n",
    "\n",
    "    return dict(\n",
    "        n=n, p=p, flip_y=flip_y, corr=corr,\n",
    "        seed=seed,\n",
    "        loss_base=loss0, loss_sam=loss1,\n",
    "        acc_base=acc0,  acc_sam=acc1,\n",
    "    )\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 3.  Simulation grid & parallel execution\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "grid = {\n",
    "    \"n\":      [4000, 20000],\n",
    "    \"p\":      [200, 500],\n",
    "    \"flip_y\": [0.05, 0.25],\n",
    "    \"corr\":   [\"low\", \"high\"],\n",
    "}\n",
    "scenarios = list(itertools.product(*grid.values()))\n",
    "N_REPS = 20   # adjust as desired\n",
    "\n",
    "jobs = [(sc, 100 + r) for sc in scenarios for r in range(N_REPS)]\n",
    "\n",
    "# Use threading backend to avoid pickling issues\n",
    "results = joblib.Parallel(n_jobs=-1, backend=\"threading\")(\n",
    "    joblib.delayed(run_once)(*job) for job in tqdm(jobs, desc=\"Sim runs\")\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 4.  Aggregate & paired t-test\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "rows = []\n",
    "for (n, p, flip, corr), grp in df.groupby([\"n\", \"p\", \"flip_y\", \"corr\"]):\n",
    "\n",
    "    t_loss, p_val = ttest_rel(grp[\"loss_base\"], grp[\"loss_sam\"])\n",
    "\n",
    "    rows.append(dict(\n",
    "        n=n, p=p, flip_y=flip, corr=corr,\n",
    "        # ▶ keep the raw means …\n",
    "        loss_base = grp[\"loss_base\"].mean(),\n",
    "        loss_sam  = grp[\"loss_sam\"].mean(),\n",
    "        acc_base  = grp[\"acc_base\"].mean(),\n",
    "        acc_sam   = grp[\"acc_sam\"].mean(),\n",
    "        # ▶ … and compute deltas for quick scanning\n",
    "        delta_loss = grp[\"loss_sam\"].mean() - grp[\"loss_base\"].mean(),\n",
    "        delta_acc  = grp[\"acc_sam\"].mean()  - grp[\"acc_base\"].mean(),\n",
    "        reps = len(grp),\n",
    "        p_loss = p_val\n",
    "    ))\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "print(summary.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3be7f9",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62316fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a5b155d88497997f465dbedba4e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Lasso sims:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>noise</th>\n",
       "      <th>corr</th>\n",
       "      <th>MSE_base</th>\n",
       "      <th>MSE_sam</th>\n",
       "      <th>ΔMSE</th>\n",
       "      <th>NZ_base</th>\n",
       "      <th>NZ_sam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>high</td>\n",
       "      <td>4720.6846</td>\n",
       "      <td>4717.7590</td>\n",
       "      <td>-2.9255</td>\n",
       "      <td>197.9</td>\n",
       "      <td>197.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>low</td>\n",
       "      <td>6592.8101</td>\n",
       "      <td>6587.0606</td>\n",
       "      <td>-5.7495</td>\n",
       "      <td>199.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>high</td>\n",
       "      <td>5100.7024</td>\n",
       "      <td>5097.7989</td>\n",
       "      <td>-2.9035</td>\n",
       "      <td>198.8</td>\n",
       "      <td>198.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>low</td>\n",
       "      <td>6981.7081</td>\n",
       "      <td>6975.9701</td>\n",
       "      <td>-5.7380</td>\n",
       "      <td>198.8</td>\n",
       "      <td>198.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000</td>\n",
       "      <td>500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>high</td>\n",
       "      <td>11790.8682</td>\n",
       "      <td>11786.1766</td>\n",
       "      <td>-4.6916</td>\n",
       "      <td>498.2</td>\n",
       "      <td>498.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>low</td>\n",
       "      <td>27441.2568</td>\n",
       "      <td>27432.1028</td>\n",
       "      <td>-9.1540</td>\n",
       "      <td>499.2</td>\n",
       "      <td>499.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4000</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>high</td>\n",
       "      <td>12189.1378</td>\n",
       "      <td>12184.4683</td>\n",
       "      <td>-4.6695</td>\n",
       "      <td>499.1</td>\n",
       "      <td>499.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>low</td>\n",
       "      <td>27812.4825</td>\n",
       "      <td>27803.3362</td>\n",
       "      <td>-9.1462</td>\n",
       "      <td>499.1</td>\n",
       "      <td>499.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>high</td>\n",
       "      <td>4568.8837</td>\n",
       "      <td>4566.0600</td>\n",
       "      <td>-2.8237</td>\n",
       "      <td>193.4</td>\n",
       "      <td>193.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>low</td>\n",
       "      <td>4086.7925</td>\n",
       "      <td>4081.5247</td>\n",
       "      <td>-5.2678</td>\n",
       "      <td>193.9</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>high</td>\n",
       "      <td>4935.6043</td>\n",
       "      <td>4932.7883</td>\n",
       "      <td>-2.8159</td>\n",
       "      <td>192.7</td>\n",
       "      <td>192.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20000</td>\n",
       "      <td>200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>low</td>\n",
       "      <td>4476.9218</td>\n",
       "      <td>4471.6491</td>\n",
       "      <td>-5.2728</td>\n",
       "      <td>194.8</td>\n",
       "      <td>194.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20000</td>\n",
       "      <td>500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>high</td>\n",
       "      <td>7694.5288</td>\n",
       "      <td>7689.8754</td>\n",
       "      <td>-4.6534</td>\n",
       "      <td>491.1</td>\n",
       "      <td>491.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20000</td>\n",
       "      <td>500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>low</td>\n",
       "      <td>11952.1948</td>\n",
       "      <td>11943.7196</td>\n",
       "      <td>-8.4752</td>\n",
       "      <td>492.5</td>\n",
       "      <td>492.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20000</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>high</td>\n",
       "      <td>8081.1718</td>\n",
       "      <td>8076.5188</td>\n",
       "      <td>-4.6530</td>\n",
       "      <td>491.4</td>\n",
       "      <td>491.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20000</td>\n",
       "      <td>500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>low</td>\n",
       "      <td>12359.6046</td>\n",
       "      <td>12351.1230</td>\n",
       "      <td>-8.4817</td>\n",
       "      <td>493.5</td>\n",
       "      <td>493.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n    p  noise  corr    MSE_base     MSE_sam    ΔMSE  NZ_base  NZ_sam\n",
       "0    4000  200    5.0  high   4720.6846   4717.7590 -2.9255    197.9   197.9\n",
       "1    4000  200    5.0   low   6592.8101   6587.0606 -5.7495    199.0   199.0\n",
       "2    4000  200   20.0  high   5100.7024   5097.7989 -2.9035    198.8   198.8\n",
       "3    4000  200   20.0   low   6981.7081   6975.9701 -5.7380    198.8   198.8\n",
       "4    4000  500    5.0  high  11790.8682  11786.1766 -4.6916    498.2   498.2\n",
       "5    4000  500    5.0   low  27441.2568  27432.1028 -9.1540    499.2   499.4\n",
       "6    4000  500   20.0  high  12189.1378  12184.4683 -4.6695    499.1   499.2\n",
       "7    4000  500   20.0   low  27812.4825  27803.3362 -9.1462    499.1   499.2\n",
       "8   20000  200    5.0  high   4568.8837   4566.0600 -2.8237    193.4   193.4\n",
       "9   20000  200    5.0   low   4086.7925   4081.5247 -5.2678    193.9   194.0\n",
       "10  20000  200   20.0  high   4935.6043   4932.7883 -2.8159    192.7   192.7\n",
       "11  20000  200   20.0   low   4476.9218   4471.6491 -5.2728    194.8   194.8\n",
       "12  20000  500    5.0  high   7694.5288   7689.8754 -4.6534    491.1   491.1\n",
       "13  20000  500    5.0   low  11952.1948  11943.7196 -8.4752    492.5   492.5\n",
       "14  20000  500   20.0  high   8081.1718   8076.5188 -4.6530    491.4   491.4\n",
       "15  20000  500   20.0   low  12359.6046  12351.1230 -8.4817    493.5   493.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools, joblib, warnings\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- helper functions ----------\n",
    "def soft_thresh(w, t):\n",
    "    return np.sign(w) * np.maximum(np.abs(w) - t, 0.)\n",
    "\n",
    "def pg_lasso_lr(X, y, lam, lr=0.01, n_iter=200):\n",
    "    n, p = X.shape\n",
    "    w = np.zeros(p)\n",
    "    for _ in range(n_iter):\n",
    "        grad = X.T @ (X @ w - y) / n\n",
    "        w -= lr * grad\n",
    "        w = soft_thresh(w, lr * lam)\n",
    "    return w\n",
    "\n",
    "def sam_pg_lasso_lr(X, y, lam, lr=0.01, rho=0.05, n_iter=200):\n",
    "    n, p = X.shape\n",
    "    w = np.zeros(p)\n",
    "    for _ in range(n_iter):\n",
    "        grad = X.T @ (X @ w - y) / n\n",
    "        norm = np.linalg.norm(grad)\n",
    "        w_adv = w + rho * grad / norm if norm > 0 else w\n",
    "        grad_adv = X.T @ (X @ w_adv - y) / n\n",
    "        w -= lr * grad_adv\n",
    "        w = soft_thresh(w, lr * lam)\n",
    "    return w\n",
    "\n",
    "# ---------- simulation grid ----------\n",
    "grid = {\n",
    "    \"n\":      [4000, 20000],\n",
    "    \"p\":      [200, 500],\n",
    "    \"noise\":  [5.0, 20.0],      # low vs high noise std\n",
    "    \"corr\":   [\"low\", \"high\"],  # correlation via effective_features\n",
    "}\n",
    "scenarios = list(itertools.product(*grid.values()))\n",
    "N_REPS = 10\n",
    "\n",
    "def run_once(params, seed, lam=0.1, rho=0.05):\n",
    "    n, p, noise_std, corr = params\n",
    "    eff = 0.3 if corr == \"low\" else 0.1  # effective sparsity ratio\n",
    "\n",
    "    X, y, coef = make_regression(\n",
    "        n_samples=n, n_features=p, n_informative=int(p*eff),\n",
    "        noise=noise_std, coef=True, random_state=seed\n",
    "    )\n",
    "    # add feature correlation if high\n",
    "    if corr == \"high\":\n",
    "        # correlate first 50 features\n",
    "        cov = 0.8\n",
    "        X[:, :50] += cov * X[:, 50:100] if p >= 100 else 0\n",
    "\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.4,\n",
    "                                              random_state=seed)\n",
    "    w0 = pg_lasso_lr(X_tr, y_tr, lam)\n",
    "    w1 = sam_pg_lasso_lr(X_tr, y_tr, lam, rho=rho)\n",
    "\n",
    "    mse0 = mean_squared_error(y_te, X_te @ w0)\n",
    "    mse1 = mean_squared_error(y_te, X_te @ w1)\n",
    "    nz0 = np.count_nonzero(w0)\n",
    "    nz1 = np.count_nonzero(w1)\n",
    "\n",
    "    return dict(n=n, p=p, noise=noise_std, corr=corr,\n",
    "                mse_base=mse0, mse_sam=mse1,\n",
    "                nz_base=nz0, nz_sam=nz1, seed=seed)\n",
    "\n",
    "jobs = [(sc, 123 + rep) for sc in scenarios for rep in range(N_REPS)]\n",
    "\n",
    "results = joblib.Parallel(n_jobs=-1, backend=\"threading\")(\n",
    "    joblib.delayed(run_once)(*job) for job in tqdm(jobs, desc=\"Lasso sims\")\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "summary = (df.groupby([\"n\",\"p\",\"noise\",\"corr\"])\n",
    "             .agg(MSE_base=(\"mse_base\",\"mean\"),\n",
    "                  MSE_sam =(\"mse_sam\",\"mean\"),\n",
    "                  ΔMSE     =(\"mse_sam\", lambda x:\n",
    "                              x.mean()-df.loc[x.index,\"mse_base\"].mean()),\n",
    "                  NZ_base =(\"nz_base\",\"mean\"),\n",
    "                  NZ_sam  =(\"nz_sam\",\"mean\"))\n",
    "             .reset_index())\n",
    "\n",
    "#\"SAM vs baseline Lasso (linear regression)\"\n",
    "summary.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9ffe5",
   "metadata": {},
   "source": [
    "### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3752d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
